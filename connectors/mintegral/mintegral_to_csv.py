import time
import hashlib
import requests
import pandas as pd
from datetime import datetime, timedelta
from io import StringIO
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

ACCOUNTS = [
    {
        'account_id': 1,
        'account_name': 'Account_1',
        'api_key': 'your_api_key_here',
        'access_key': 'your_access_key_here',
        'active': True
    },
    {
        'account_id': 1,
        'account_name': 'Account_2',
        'api_key': 'your_api_key_here',
        'access_key': 'your_access_key_here',
        'active': True
    }
    # –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ –∞–∫–∫–∞—É–Ω—Ç—ã –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏
]

GLOBAL_DATE_FROM = 'your_start_date_here'  # –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∫–∞–±–∏–Ω–µ—Ç–æ–≤
GLOBAL_DATE_TO = 'your_end_date_here'  # –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è (–∏–ª–∏ '' –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –¥–æ –≤—á–µ—Ä–∞)

DEFAULT_TIMEZONE = '+3'
MAX_RETRIES = 15
RETRY_DELAY = 45
REQUEST_TIMEOUT = 120
MAX_CONSECUTIVE_ERRORS = 3


class MintegralAPIClient:
    def __init__(self, account_config: dict):
        self.account_id = account_config['account_id']
        self.account_name = account_config['account_name']
        self.api_key = account_config['api_key']
        self.access_key = account_config['access_key']
        self.active = account_config['active']

    def get_token(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        timestamp = str(int(time.time()))
        timestamp_md5 = hashlib.md5(timestamp.encode()).hexdigest()
        token = hashlib.md5((self.api_key + timestamp_md5).encode()).hexdigest()
        return token, timestamp

    def make_api_request(self, type_value, start_date, end_date, dimension_option='Offer',
                         time_granularity='daily', timezone=DEFAULT_TIMEZONE):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ API"""
        params = {
            'start_time': start_date,
            'end_time': end_date,
            'type': type_value,
            'dimension_option': dimension_option,
            'time_granularity': time_granularity,
            'timezone': timezone
        }

        token, timestamp = self.get_token()
        headers = {
            'access-key': self.access_key,
            'token': token,
            'timestamp': timestamp,
            'Content-Type': 'application/json'
        }

        url = 'https://ss-api.mintegral.com/api/v2/reports/data'

        try:
            response = requests.get(url, params=params, headers=headers, timeout=REQUEST_TIMEOUT)
            return response
        except requests.exceptions.RequestException as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {self.account_name}: {e}")
            return None

    def test_api_connection(self):
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API"""
        try:
            test_date = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')
            response = self.make_api_request(1, test_date, test_date, 'Offer', 'daily')
            return response and (response.ok or response.status_code in [400, 401])
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è API –¥–ª—è {self.account_name}: {e}")
            return False

    def wait_for_data_generation(self, start_date, end_date, dimension_option='Offer',
                                 time_granularity='daily', max_retries=MAX_RETRIES):
        """–û–∂–∏–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ"""
        consecutive_errors = 0

        for attempt in range(max_retries):
            try:
                response = self.make_api_request(1, start_date, end_date, dimension_option, time_granularity)

                if not response:
                    consecutive_errors += 1
                    if consecutive_errors >= MAX_CONSECUTIVE_ERRORS:
                        return False
                    if attempt < max_retries - 1:
                        wait_time = RETRY_DELAY * (1 + consecutive_errors * 0.5)
                        logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {wait_time}—Å –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                        time.sleep(wait_time)
                    continue

                consecutive_errors = 0

                if not response.ok:
                    if attempt < max_retries - 1:
                        logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö... –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}")
                        time.sleep(RETRY_DELAY)
                    continue

                try:
                    data = response.json()
                except:
                    if attempt < max_retries - 1:
                        time.sleep(RETRY_DELAY)
                    continue

                code = data.get('code')

                if code == 200:
                    logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è {self.account_name}")
                    return True
                elif code in [201, 202]:
                    if attempt < max_retries - 1:
                        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö... –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}")
                        time.sleep(RETRY_DELAY)
                    continue
                else:
                    logger.warning(f"‚ùå API –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {code} –¥–ª—è {self.account_name}")
                    return False

            except Exception as e:
                consecutive_errors += 1
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∂–∏–¥–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
                if consecutive_errors >= MAX_CONSECUTIVE_ERRORS:
                    return False
                if attempt < max_retries - 1:
                    wait_time = RETRY_DELAY * (1 + consecutive_errors * 0.5)
                    time.sleep(wait_time)

        return False

    def download_data(self, start_date, end_date, dimension_option='Offer', time_granularity='daily'):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        response = self.make_api_request(2, start_date, end_date, dimension_option, time_granularity)

        if not response or not response.ok:
            return None

        content_type = response.headers.get('Content-Type', '')
        if 'application/octet-stream' in content_type or 'text/plain' in content_type:
            return response.text
        return None

    def get_data_for_period(self, start_date, end_date, dimension_option='Offer', time_granularity='daily'):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        logger.info(f"–ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è {self.account_name} –∑–∞ {start_date} - {end_date}")

        if not self.wait_for_data_generation(start_date, end_date, dimension_option, time_granularity):
            logger.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {self.account_name}")
            return None

        return self.download_data(start_date, end_date, dimension_option, time_granularity)

    def parse_data_to_dataframe(self, data_text):
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –≤ DataFrame"""
        if not data_text or not data_text.strip():
            return None

        try:
            df = pd.read_csv(StringIO(data_text), sep='\t')
            return df if not df.empty else None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {self.account_name}: {e}")
            return None


def convert_date_format(date_str: str, from_format: str, to_format: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã"""
    try:
        date_obj = datetime.strptime(date_str, from_format)
        return date_obj.strftime(to_format)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –¥–∞—Ç—ã {date_str}: {e}")
        return date_str


def split_date_range(start_date, end_date, days=7):
    """–†–∞–∑–±–∏–≤–∫–∞ –ø–µ—Ä–∏–æ–¥–∞ –Ω–∞ —á–∞—Å—Ç–∏ (API –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–∞–∫—Å–∏–º—É–º 7 –¥–Ω–µ–π)"""
    start = datetime.strptime(start_date, '%Y-%m-%d')
    end = datetime.strptime(end_date, '%Y-%m-%d')
    date_ranges = []
    current = start

    while current <= end:
        next_date = min(current + timedelta(days=days - 1), end)
        date_ranges.append((
            current.strftime('%Y-%m-%d'),
            next_date.strftime('%Y-%m-%d')
        ))
        current = next_date + timedelta(days=1)

    return date_ranges


def transform_to_target_format(df, account_id, account_name):
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ü–µ–ª–µ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç"""
    if df.empty:
        return pd.DataFrame()

    result_df = pd.DataFrame()

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–∫–∫–∞—É–Ω—Ç–µ - –ò–°–ü–†–ê–í–õ–ï–ù–û
    result_df['account_id'] = account_id
    result_df['account_name'] = account_name

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
    if 'Date' in df.columns:
        result_df['date'] = pd.to_datetime(df['Date'], format='%Y%m%d').dt.strftime('%Y-%m-%d')
    else:
        result_df['date'] = ''

    # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–º–ø–∞–Ω–∏–∏
    if 'Offer Name' in df.columns:
        result_df['campaign_name'] = df['Offer Name']
    else:
        result_df['campaign_name'] = 'Unknown Campaign'

    # –ú–µ—Ç—Ä–∏–∫–∏ - –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
    if 'Impression' in df.columns:
        result_df['impression'] = pd.to_numeric(df['Impression'], errors='coerce').fillna(0).astype(int)
    else:
        result_df['impression'] = 0

    if 'Click' in df.columns:
        result_df['clicks'] = pd.to_numeric(df['Click'], errors='coerce').fillna(0).astype(int)
    else:
        result_df['clicks'] = 0

    if 'Spend' in df.columns:
        result_df['spend_in_dollars'] = pd.to_numeric(df['Spend'], errors='coerce').fillna(0).round(4)
    else:
        result_df['spend_in_dollars'] = 0.0

    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ account_id –∏ account_name –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫
    result_df['account_id'] = result_df['account_id'].fillna(account_id)
    result_df['account_name'] = result_df['account_name'].fillna(account_name)

    return result_df.sort_values(['date', 'campaign_name']).reset_index(drop=True)


def process_account(account_config: dict, start_date: str, end_date: str) -> pd.DataFrame:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞"""
    account_name = account_config['account_name']

    logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç: {account_name}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–∫–∫–∞—É–Ω—Ç–∞
    if not account_config.get('active', True):
        logger.warning(f"–ê–∫–∫–∞—É–Ω—Ç {account_name} –æ—Ç–∫–ª—é—á–µ–Ω")
        return pd.DataFrame()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if not account_config.get('api_key') or not account_config.get('access_key'):
        logger.error(f"–ù–µ —É–∫–∞–∑–∞–Ω—ã API_KEY/ACCESS_KEY –¥–ª—è {account_name}")
        return pd.DataFrame()

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ API
        client = MintegralAPIClient(account_config)

        # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        if not client.test_api_connection():
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API –¥–ª—è {account_name}")
            return pd.DataFrame()

        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–µ—Ä–∏–æ–¥ –Ω–∞ —á–∞—Å—Ç–∏ (–º–∞–∫—Å–∏–º—É–º 7 –¥–Ω–µ–π –Ω–∞ –∑–∞–ø—Ä–æ—Å)
        date_ranges = split_date_range(start_date, end_date, days=7)
        logger.info(f"–ü–µ—Ä–∏–æ–¥ —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(date_ranges)} —á–∞—Å—Ç–µ–π –¥–ª—è {account_name}")

        all_dataframes = []
        successful_periods = 0
        failed_periods = 0

        for i, (period_start, period_end) in enumerate(date_ranges, 1):
            logger.info(f"[{i}/{len(date_ranges)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {period_start} - {period_end} –¥–ª—è {account_name}")

            try:
                data_text = client.get_data_for_period(period_start, period_end, 'Offer', 'daily')

                if data_text:
                    df = client.parse_data_to_dataframe(data_text)
                    if df is not None:
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ü–µ–ª–µ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
                        transformed_df = transform_to_target_format(df, account_config['account_id'], account_name)
                        all_dataframes.append(transformed_df)
                        successful_periods += 1
                        logger.info(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(transformed_df)} –∑–∞–ø–∏—Å–µ–π")
                    else:
                        failed_periods += 1
                        logger.warning(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ {period_start} - {period_end}")
                else:
                    failed_periods += 1
                    logger.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–µ—Ä–∏–æ–¥ {period_start} - {period_end}")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä–∏–æ–¥–∞ {period_start} - {period_end}: {e}")
                failed_periods += 1

        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è {account_name}: {successful_periods}")
        logger.info(f"‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è {account_name}: {failed_periods}")

        if all_dataframes:
            final_df = pd.concat(all_dataframes, ignore_index=True)
            logger.info(f"üìä –ò—Ç–æ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è {account_name}: {len(final_df)}")
            return final_df
        else:
            logger.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {account_name}")
            return pd.DataFrame()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞–∫–∫–∞—É–Ω—Ç–∞ {account_name}: {e}")
        return pd.DataFrame()


def main():
    print("MINTEGRAL DATA EXPORT TO CSV")
    print("=" * 50)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–∫–∫–∞—É–Ω—Ç–æ–≤
    if not ACCOUNTS:
        logger.error("–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∏ –æ–¥–∏–Ω –∞–∫–∫–∞—É–Ω—Ç!")
        return

    active_accounts = [a for a in ACCOUNTS if a.get('active', True)]
    if not active_accounts:
        logger.error("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤!")
        return

    logger.info(f"–ê–∫—Ç–∏–≤–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {len(active_accounts)}")

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∞
    start_date = GLOBAL_DATE_FROM

    # –ï—Å–ª–∏ GLOBAL_DATE_TO –ø—É—Å—Ç–∞—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å
    if GLOBAL_DATE_TO == '' or not GLOBAL_DATE_TO:
        end_date = (datetime.now() - timedelta(days=1)).strftime('%d.%m.%Y')
        logger.info(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∫–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞: {end_date} (–≤—á–µ—Ä–∞)")
    else:
        end_date = GLOBAL_DATE_TO

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç
    try:
        datetime.strptime(start_date, '%d.%m.%Y')
        datetime.strptime(end_date, '%d.%m.%Y')
        logger.info(f"–ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –≤—ã–≥—Ä—É–∑–∫–∏: {start_date} - {end_date}")
    except ValueError:
        logger.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –¥–∞—Ç! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DD.MM.YYYY")
        return

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç API
    api_date_from = convert_date_format(start_date, '%d.%m.%Y', '%Y-%m-%d')
    api_date_to = convert_date_format(end_date, '%d.%m.%Y', '%Y-%m-%d')

    logger.info(f"API –ø–µ—Ä–∏–æ–¥: {api_date_from} - {api_date_to}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞
    all_dataframes = []

    for account_config in ACCOUNTS:
        if account_config.get('active', True):
            df = process_account(account_config, api_date_from, api_date_to)
            if not df.empty:
                all_dataframes.append(df)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    if all_dataframes:
        final_df = pd.concat(all_dataframes, ignore_index=True)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'mintegral_data_{timestamp}.csv'

        final_df.to_csv(filename, index=False, encoding='utf-8')

        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
        logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(final_df)}")
        logger.info(f"üè¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {final_df['account_name'].nunique()}")
        logger.info(f"üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞–º–ø–∞–Ω–∏–π: {final_df['campaign_name'].nunique()}")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {final_df['date'].min()} - {final_df['date'].max()}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
        total_impressions = final_df['impression'].sum()
        total_clicks = final_df['clicks'].sum()
        total_spend = final_df['spend_in_dollars'].sum()
        logger.info(f"üí∞ –ü–æ–∫–∞–∑–æ–≤: {total_impressions:,}, –ö–ª–∏–∫–æ–≤: {total_clicks:,}, –†–∞—Å—Ö–æ–¥—ã: ${total_spend:,.2f}")

    else:
        logger.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")


if __name__ == '__main__':
    main()